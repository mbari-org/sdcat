[cluster]
########################################################################
# Settings related to clustering
########################################################################
# The minimum score of a detection to be considered for clustering; set to 0 to keep all detections
min_score = 0.0
# Location of the data to cluster - only used if day/night filtering is enabled
# Monterey Bay
latitude = 36.7253
longitude = -121.7840
# Remove detections in the 1% of images. Useful to remove false detections from imager
# artifacts
remove_corners = False
# Minimum saliency of a detection to be considered for clustering; set to 0 to keep all detections
min_saliency = 30
# Alpha is a parameter that controls the linkage. Don't change it unless you know what you are doing.
# See https://hdbscan.readthedocs.io/en/latest/parameter_selection.html
alpha = 0.92
# Epsilon is a parameter that controls the linkage. Don't change it unless you know what you are doing.
# Increasing this will make the clustering more conservative
cluster_selection_epsilon = 0.0
# The method used to select clusters from the condensed tree. leaf is the most conservative; eom is the most aggressive
cluster_selection_method = leaf
# The minimum number of samples in a group for that group to be
# considered a cluster; groupings smaller than this size will be left
# as noise. This must be set to at least 2.
min_cluster_size = 2
# The number of samples in a neighborhood for a point
# to be considered as a core point. This includes the point itself.
min_samples = 1
max_area = 4375000
min_area = 100
# Detections not assigned with hdbscan are assigned to the nearest cluster with a similarity > min_similarity
# This is useful for merging examples not assigned to clusters; set to 0 to disable
# A value of .9 would be very conservative, while a value of .5 would be very aggressive (merging only somewhat similar detections)
# min_similarity must be in the range [0, 1]
min_similarity = 0.70
# google/vit-base-patch16-224 is a model trained on ImageNet21k with 21k classes good for general detection
# dino models were pretrained on ImageNet which contains 1.3 M images with labels from 1000 classes
# Smaller block_size means more patches and more accurate fine-grained clustering on smaller objects
# Larger block_size means fewer patches and faster processing
model = google/vit-base-patch16-224
;model = facebook/dino-vits8
;model = facebook/dino-vits16

[detect]
########################################################################
# Settings related to sliced detection
########################################################################
max_area = 4375000
min_area = 1
min_saliency = 30
# Run the CLAHE algorithm to contrast enhance before detection useful images with non-uniform lighting
clahe = False
# These classes are the ones that showed the best performance in hustvl/yolos-small model for general detection
;allowable_classes = person,airplane,boat,bird,kite,surfboard,dog,frisbee,horse,tennis ball,sports ball,animal
# By setting class_agnostic to True, the model will not use the class information to filter out detections
class_agnostic = False
# Leave blank for all classes
allowable_classes =
